{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount my google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg84gfFwycJc",
        "outputId": "7cf74d76-b943-4bd3-dd32-59f3d4095f12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1HysyA_zvndQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input, Embedding, LayerNormalization, Dropout\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/training_data.txt', 'r', encoding='utf-8') as f:\n",
        "    data = f.read().replace('\\n', ' ')"
      ],
      "metadata": {
        "id": "DTnHlqEbv6ba"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG8sEiJOv96p",
        "outputId": "7d393979-9ee3-4ac9-cf6c-4fd60a79c347"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "characters=list(set(list(data)))\n",
        "print(len(characters))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo8Sywe2wGo7",
        "outputId": "dac8e932-dad9-4d40-adfd-025b3bd04bed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "character_to_integer_encoding={}\n",
        "integer_to_character_encoding={}\n",
        "for i in range(len(characters)):\n",
        "    character_to_integer_encoding[characters[i]]=i+1\n",
        "    integer_to_character_encoding[i+1]=characters[i]"
      ],
      "metadata": {
        "id": "GeX0WxABwJbr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(string):\n",
        "    global character_to_integer_encoding\n",
        "    return [character_to_integer_encoding[char] for char in string]\n",
        "\n",
        "def decode(lst):\n",
        "    global integer_to_character_encoding\n",
        "    return ''.join([integer_to_character_encoding[i] for i in lst])"
      ],
      "metadata": {
        "id": "T6m-JJ-zwLFp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data=encode(data)\n",
        "train_data=input_data[:int(0.9*len(input_data))]\n",
        "test_data=input_data[int(0.9*len(input_data)):]"
      ],
      "metadata": {
        "id": "PfPyDYSCwMw2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16\n",
        "block_size=64\n",
        "num_heads=4 # Experiment with other values if you want\n",
        "num_transformer_blocks = 3\n",
        "input_vocab_size=len(characters)+1\n",
        "feed_forward_dim = 256"
      ],
      "metadata": {
        "id": "SxE97O-0wO5v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def causal_attention_mask(batch_size, n_dest, n_src):\n",
        "    i = tf.range(n_dest)[:, None]\n",
        "    j = tf.range(n_src)\n",
        "    m = i >= j - n_src + n_dest\n",
        "    mask = tf.cast(m, tf.bool)\n",
        "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "    mult = tf.concat(\n",
        "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "    )\n",
        "    return tf.tile(mask, mult)\n",
        "\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.3):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        # Give code for an attention layer, feedforward layers, and normalization layers. The attention layer is first, then normalization and dropout, then forward the data passed through a non-linear function, and call the dropout layer again\n",
        "        self.att = layers.MultiHeadAttention(num_heads, embed_dim)\n",
        "        self.feed_forward_network = Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
        "        )\n",
        "        self.normalization_layer_1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.normalization_layer_2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        block_size = input_shape[1]\n",
        "        causal_mask = causal_attention_mask(batch_size, block_size, block_size)\n",
        "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
        "        attention_output = self.dropout1(attention_output)\n",
        "        out1 = self.normalization_layer_1(inputs + attention_output)\n",
        "        feed_forward_output = self.feed_forward_network(out1)\n",
        "        feed_forward_output = self.dropout2(feed_forward_output)\n",
        "        return self.normalization_layer_2(out1 + feed_forward_output)"
      ],
      "metadata": {
        "id": "VvO4m9PowRma"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_embedding = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_embedding = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_embedding(positions)\n",
        "        x = self.token_embedding(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "P72oYzT9wTa1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(Model):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim, num_heads, feed_forward_dim, num_transformer_blocks):\n",
        "        super().__init__()\n",
        "        self.inputs = Input(shape=(maxlen,), dtype=tf.int32)\n",
        "        self.embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "        self.embedding_dim = embed_dim\n",
        "        self.num_transformer_blocks = num_transformer_blocks\n",
        "        self.transformer_blocks = [TransformerBlock(embed_dim, num_heads, feed_forward_dim) for _ in range(num_transformer_blocks)]\n",
        "        self.dense = Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding_layer(inputs)\n",
        "        for i in range(self.num_transformer_blocks):\n",
        "            x = self.transformer_blocks[i](x)\n",
        "        output = self.dense(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "def get_transformer_model(\n",
        "    maxlen,\n",
        "    vocab_size,\n",
        "    embed_dim,\n",
        "    num_heads,\n",
        "    feed_forward_dim,\n",
        "    num_transformer_blocks=1\n",
        "):\n",
        "    inputs = Input(shape=(maxlen,), dtype=tf.int32)\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    for i in range(num_transformer_blocks):\n",
        "        transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
        "        x = transformer_block(x)\n",
        "    outputs = Dense(vocab_size)(x)\n",
        "    model = Model(inputs=inputs, outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "XtBLbLMJwWTQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_transformer_model(\n",
        "    block_size,\n",
        "    input_vocab_size,\n",
        "    feed_forward_dim,\n",
        "    num_heads,\n",
        "    feed_forward_dim,\n",
        "    num_transformer_blocks\n",
        ")\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(\n",
        "    \"adam\",\n",
        "    loss=[loss_fn],\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "znbyWHLhwXxY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [train_data[i:i+block_size] for i in range(0, len(train_data)-block_size-1)]\n",
        "targets = [train_data[i+1:i+block_size+1] for i in range(0, len(train_data)-block_size-1)]\n",
        "\n",
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=block_size, padding='post')\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=block_size, padding='post')\n",
        "\n",
        "inputs = tf.convert_to_tensor(inputs, dtype=tf.int64)\n",
        "targets = tf.convert_to_tensor(targets, dtype=tf.int64)\n",
        "\n",
        "dataset= tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
        "dataset = dataset.shuffle(10000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "mfn_hen5wZZw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "Qor7ThBrwbNl",
        "outputId": "55158d75-be11-4a37-8f61-79436fadf3a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block_4                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m1,184,512\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block_5                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m1,184,512\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block_6                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m1,184,512\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m)              │          \u001b[38;5;34m16,705\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block_4                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,184,512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block_5                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,184,512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block_6                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,184,512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,705</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,603,265\u001b[0m (13.75 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,603,265</span> (13.75 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,603,265\u001b[0m (13.75 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,603,265</span> (13.75 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
        "dataset=dataset.shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "model.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMtgJjtnwdTp",
        "outputId": "f8111061-2dd5-4811-a017-7ca8b6dca799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m 2359/62736\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:20:18\u001b[0m 974ms/step - accuracy: 0.5310 - loss: 1.6209"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_index, num_generate=1):\n",
        "    # Ensure train_data[start_index:start_index + block_size] is properly shaped\n",
        "    input_sequence = train_data[start_index:start_index + block_size]\n",
        "    generated_text = decode(input_sequence)\n",
        "    probabilistic_text = decode(input_sequence)\n",
        "    for i in range(num_generate):\n",
        "        input_eval = tf.convert_to_tensor([input_sequence], dtype=tf.int32)\n",
        "        predictions = model.predict(input_eval)\n",
        "        probabilities = tf.nn.softmax(predictions[0, -1]).numpy()\n",
        "        next_token = np.random.choice(len(probabilities), p=probabilities)\n",
        "        next_token = np.argmax(probabilities)\n",
        "        input_sequence += [next_token]\n",
        "        input_sequence = input_sequence[1:]\n",
        "        generated_text += decode([next_token])\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "IV17351ywfnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model, start_index=len(train_data)-block_size, num_generate=1000)"
      ],
      "metadata": {
        "id": "KBrjHiQmwiak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c9WSn4jfwzI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('transformer_model.weights.h5')"
      ],
      "metadata": {
        "id": "L3hkVZVkwx9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"saved_model.keras\")"
      ],
      "metadata": {
        "id": "6R_VINPRw0-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTING THE ACCURACY**"
      ],
      "metadata": {
        "id": "aLWb8XDYxLqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a test dataset available (similar to the train dataset)\n",
        "test_inputs = [test_data[i:i + block_size] for i in range(0, len(test_data) - block_size - 1)]\n",
        "test_targets = [test_data[i + 1:i + block_size + 1] for i in range(0, len(test_data) - block_size - 1)]\n",
        "\n",
        "test_inputs = tf.keras.preprocessing.sequence.pad_sequences(test_inputs, maxlen=block_size, padding='post')\n",
        "test_targets = tf.keras.preprocessing.sequence.pad_sequences(test_targets, maxlen=block_size, padding='post')\n",
        "\n",
        "test_inputs = tf.convert_to_tensor(test_inputs, dtype=tf.int64)\n",
        "test_targets = tf.convert_to_tensor(test_targets, dtype=tf.int64)\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_inputs, test_targets))\n",
        "test_dataset = test_dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "id": "VagjymiuxRR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**block_size = 64**  # Reduced block size for faster training and to prevent overfitting\n",
        "\n",
        "\n",
        "**num_heads = 4**   # Lower number of attention heads to reduce model complexity\n",
        "\n",
        "\n",
        "**num_transformer_blocks = 3**  # Reduced layers to avoid overfitting\n",
        "\n",
        "\n",
        "**feed_forward_dim = 128**  # Smaller feed-forward dimensions to reduce model complexity\n",
        "\n",
        "\n",
        "**dropout_rate = 0.3**  # Increased dropout to prevent overfitting\n",
        "\n",
        "\n",
        "**batch_size = 16**  # Smaller batch size for better generalization\n",
        "\n"
      ],
      "metadata": {
        "id": "Gw9a6DAY2cRz"
      }
    }
  ]
}